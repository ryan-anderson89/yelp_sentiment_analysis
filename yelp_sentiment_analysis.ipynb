{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yelp API client required: !pip install yelp\n",
    "#also need an API key from yelp's developer site\n",
    "\n",
    "from yelp.client import Client\n",
    "from yelp.oauth1_authenticator import Oauth1Authenticator\n",
    "\n",
    "secrets = dict()\n",
    "with open('secrets.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        k, v = line.split()\n",
    "        secrets[k] = v\n",
    "        \n",
    "auth = Oauth1Authenticator(**secrets)\n",
    "client = Client(auth)\n",
    "\n",
    "params = {\n",
    "    'term': 'restaurants',\n",
    "    'lang': 'en'\n",
    "}\n",
    "\n",
    "response = client.search('Oakland', **params)\n",
    "first_business = response.businesses[0]\n",
    "a_business = client.get_business(business_id=first_business.id)\n",
    "a_business.business.reviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was going to use the API to pull a set of reviews for analysis,\n",
    "but unfortunately Yelp only allows a single review per business to be returned via API. I'd rather not write a web scraper since that would be pretty clearly violating what Yelp allows, but maybe there's another way.\n",
    "\n",
    "Kaggle.com offers a lot of datasets - fortunately they have an aggregated yelp dataset at https://www.kaggle.com/c/yelp-recsys-2013/data. We'll download and unzip this data into the ./data/yelp_training_set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "import json\n",
    "import string\n",
    "\n",
    "labels, reviews = [], []\n",
    "\n",
    "#Normally, I would use pandas.read_json functionality to quickly load the data,\n",
    "#but this particular dataset is causing errors - since we only care about\n",
    "#the stars and review text at this point, doing it directly is easy enough.\n",
    "\n",
    "with open('./data/yelp_training_set/yelp_training_set_review.json', 'r') as f:\n",
    "    data = [line.strip() for line in f]\n",
    "    \n",
    "for line in data:\n",
    "    review = json.loads(line)\n",
    "    labels.append(review['stars'])\n",
    "    reviews.append(review['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229907\n",
      "\n",
      "1\n",
      "\n",
      "I have no idea why some people...\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print()\n",
    "print(labels[0])\n",
    "print()\n",
    "print(reviews[1][:30]+'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good - we now have 230K reviews with a star rating and the review text. Next, we'll split this data into a training and test set to make sure we're evaluating our performance fairly, then set up a pipeline to perform a term-frequency/inverse-document-frequency transformation on the data, and then run a SGD Classifier using the transformed test data and the test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier())\n",
    "                     ])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now trained, so let's try to predict the labels of the held-out test data and see how performance looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.76      0.63      4402\n",
      "          2       0.50      0.15      0.23      5097\n",
      "          3       0.50      0.15      0.23      8882\n",
      "          4       0.52      0.55      0.54     20030\n",
      "          5       0.59      0.81      0.68     19066\n",
      "\n",
      "avg / total       0.54      0.56      0.52     57477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that bad! >50% classification accuracy with 5 labels suggests that we're at least detecting some signal. The model does seem to be better at the extremes of the rating scales (1 or 5), and is a bit mushier in the middle and under-predicts 2, 3 or 4.\n",
    "\n",
    "But, maybe we don't need that level of detail - what if we just wanted to know if the review was positive (4 or 5) vs. neutral to bad (1-3)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.68      0.76     18505\n",
      "          1       0.86      0.94      0.90     38972\n",
      "\n",
      "avg / total       0.86      0.86      0.85     57477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = [0 if l < 4 else 1 for l in labels]\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier())\n",
    "                     ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels)\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better accuracy! The model does a quite good job of finding positive reviews, although it still under-classifies negative reviews. We might be able to adjust this by balancing the class weights or otherwise trying to balance the data, but as-is the classifer is doing a pretty good job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
